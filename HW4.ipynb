{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "import random\n",
    "from IPython.core.display import Image, display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE_ID = 0\n",
    "DEVICE = torch.device('cuda:%d' % DEVICE_ID)\n",
    "torch.cuda.set_device(DEVICE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTYPE = torch.float32\n",
    "print_every = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100500)\n",
    "\n",
    "def data2image(data):\n",
    "    res = np.transpose(np.reshape(data ,(3, 32,32)), (1,2,0))\n",
    "    return PIL.Image.fromarray(np.uint8(res))\n",
    "\n",
    "def imshow(img):\n",
    "    if isinstance(img, torch.Tensor): img = img.numpy().astype('uint8')\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "    \n",
    "def prediction2classes(output_var):\n",
    "    _, predicted = torch.max(output_var.data, 1)\n",
    "    predicted.squeeze_()\n",
    "    classes = predicted.tolist()\n",
    "    return classes\n",
    "\n",
    "def make_solution_pytorch(net, input_tensor, a_batch_size):\n",
    "    res = []\n",
    "    net = net.eval()\n",
    "    cur_pos = 0\n",
    "    while cur_pos <= len(input_tensor):\n",
    "        outputs = net(input_tensor[cur_pos:cur_pos+a_batch_size])\n",
    "        res += prediction2classes(outputs)\n",
    "        cur_pos += a_batch_size\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "\n",
    "class CifarDataset(Dataset):\n",
    "    def __init__(self, input_path, is_train=True, transform=None):\n",
    "                        \n",
    "        data = np.load(input_path)\n",
    "        if is_train: \n",
    "            self.Y, self.X = np.hsplit(data, [1]) \n",
    "            self.Y = [item[0] for item in self.Y]\n",
    "        else: \n",
    "            self.X = data\n",
    "            self.Y = None\n",
    "            \n",
    "        self.X = self.X.reshape((self.X.shape[0], 3, 32, 32))\n",
    "        self.X = self.X.transpose((0, 2, 3, 1)) #приводим к виду (N, H, W, C)\n",
    "        self.X = [Image.fromarray(img) for img in self.X]\n",
    "                \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        sample = self.X[idx]\n",
    "\n",
    "        if self.transform: sample = self.transform(sample)\n",
    "\n",
    "        if self.Y is None: return sample\n",
    "        else: return (sample, self.Y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "firstData = dset.CIFAR100('cifar-100-python/', train=True, download=True, transform = transforms.ToTensor())\n",
    "np_mean = np.mean([item[0].numpy() for item in firstData], axis=(0,2,3))\n",
    "np_std = np.std([item[0].numpy() for item in firstData], axis=(0,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN = 49000\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.FloatTensor(np_mean), torch.FloatTensor(np_std))\n",
    "]\n",
    ")\n",
    "\n",
    "cifar_test_transform_norm = transforms.Compose([    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.FloatTensor(np_mean), torch.FloatTensor(np_std))\n",
    "]\n",
    ")\n",
    "\n",
    "data_train = dset.CIFAR100('cifar-100-python/', train=True, download=True, transform = transform)\n",
    "                 \n",
    "loader_train = DataLoader(data_train, batch_size=BATCH_SIZE, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "                                 \n",
    "data_val = dset.CIFAR100('cifar-100-python/', train=True, download=True, transform=transform)                \n",
    "loader_val = DataLoader(data_val, batch_size=BATCH_SIZE, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH  = '/home/neo/04/'\n",
    "train_path = 'homework_4.train.npy'\n",
    "test_path  = 'homework_4_no_classes.test.npy'\n",
    "dataset_test_norm = CifarDataset(DATA_PATH + test_path, is_train=False, transform=cifar_test_transform_norm)\n",
    "dataloader_test_norm = DataLoader(dataset_test_norm, batch_size=128,\n",
    "                        shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=DEVICE, dtype=DTYPE)  # move to device, e.g. GPU\n",
    "            y = y.to(device=DEVICE, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, epochs=1):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model = model.to(device=DEVICE) \n",
    "    for e in range(epochs):\n",
    "        model.train()\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            x = x.to(device=DEVICE, dtype=DTYPE)\n",
    "            y = y.to(device=DEVICE, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            loss = criterion(scores, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        \n",
    "        print('epoch %d, loss = %.4f' % (e, loss.item()))\n",
    "        check_accuracy(loader_val, model)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ma sweet machinery\n",
    "\n",
    "#Tricky, Max pool and Avg pool\n",
    "def speciallyResizedX(x):\n",
    "    maxPool = nn.MaxPool2d(3, 2, 1)\n",
    "    avgPool = nn.AvgPool2d(3, 2, 1)\n",
    "    N, C, H, W = x.size()\n",
    "    newX = torch.zeros((N, C * 2, int(H / 2), int(W / 2)))\n",
    "    newX[:, 0 : C, :, :] = maxPool(x)\n",
    "    newX[:, C : 2 * C, :, :] = avgPool(x)\n",
    "    return newX\n",
    "\n",
    "\n",
    "# Conv + BatchNorm + Relu at the end\n",
    "class ComplicatedConvolutionalLayer(nn.Module):\n",
    "    def __init__(self, channels, noRelu = False):\n",
    "        super(ComplicatedConvolutionalLayer, self).__init__()\n",
    "        self.noRelu = noRelu\n",
    "        \n",
    "        self.conv = nn.Conv2d(channels, channels,  stride=1,\n",
    "                     kernel_size=3, padding=1, bias=False)\n",
    "        self.batchNorm = nn.BatchNorm2d(channels)\n",
    "        if not noRelu:\n",
    "            self.relu = nn.LeakyReLU()\n",
    "            \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchNorm(x)\n",
    "        if not self.noRelu:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "                 \n",
    "        \n",
    "#double amount of chanels while downsampling twice\n",
    "#Actually, only another kernel size = 3, just curiosity\n",
    "class DownsamplingConvolutionalLayer(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(DownsamplingConvolutionalLayer, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(channels, 2 * channels,  stride=2,\n",
    "                     kernel_size=3, padding=1, bias=False)\n",
    "        self.batchNorm = nn.BatchNorm2d(2 * channels)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchNorm(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarResidualBlock(nn.Module):\n",
    "    def __init__(self, a_in_channels, make_downsample=False, use_skip_connection=True):\n",
    "        super(CifarResidualBlock, self).__init__()\n",
    "        self.use_skip_connection = use_skip_connection\n",
    "        self.downsample = make_downsample\n",
    "        if not make_downsample:\n",
    "            self.conv1 = ComplicatedConvolutionalLayer(a_in_channels)\n",
    "            self.conv2 = ComplicatedConvolutionalLayer(a_in_channels, noRelu = True)\n",
    "            self.lastRelu = nn.LeakyReLU()\n",
    "        else:\n",
    "            self.conv1 = DownsamplingConvolutionalLayer(a_in_channels)\n",
    "            self.conv2 = ComplicatedConvolutionalLayer(2 * a_in_channels, noRelu = True)\n",
    "            self.lastRelu = nn.LeakyReLU()\n",
    "            \n",
    "            \n",
    "    def forward(self, x):\n",
    "        if self.use_skip_connection:\n",
    "            if self.downsample:\n",
    "                variableToSaveX = speciallyResizedX(x)\n",
    "            else:\n",
    "                variableToSaveX = x.clone()\n",
    "            x = self.conv1(x)\n",
    "            x = self.conv2(x)\n",
    "            x = self.lastRelu(x + variableToSaveX)\n",
    "        else:\n",
    "            x = self.conv1(x)\n",
    "            x = self.conv2(x)\n",
    "            x = self.lastRelu(x)        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv + BatchNorm + Relu at the end + an ability to vary parameters!\n",
    "\n",
    "class MoreComplicatedConvolutionalLayer(nn.Module):\n",
    "    def __init__(self, inChannels, outChannels, kernelSize = 3, noRelu = False):\n",
    "        super(MoreComplicatedConvolutionalLayer, self).__init__()\n",
    "        self.noRelu = noRelu\n",
    "        \n",
    "        if (kernelSize == 3):\n",
    "            computedPadding = 1\n",
    "        else:\n",
    "            computedPadding = 0\n",
    "        \n",
    "        self.conv = nn.Conv2d(inChannels, outChannels, stride=1, kernel_size=kernelSize, padding=computedPadding, bias=False)\n",
    "        self.drop = nn.Dropout2d(0.01)\n",
    "        self.batchNorm = nn.BatchNorm2d(outChannels)\n",
    "        if not noRelu:\n",
    "            self.relu = nn.LeakyReLU()\n",
    "            \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)  \n",
    "        x = self.drop(x)\n",
    "        x = self.batchNorm(x)\n",
    "        if not self.noRelu:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOTTLENECK_COEF = 4\n",
    "BOTTLENECK_KERNEL = 1\n",
    "\n",
    "class CifarResidualBottleneckBlock(nn.Module):\n",
    "    def __init__(self, inChannels, make_downsample=False, use_skip_connection=True):\n",
    "        super(CifarResidualBottleneckBlock, self).__init__()\n",
    "        self.use_skip_connection = use_skip_connection\n",
    "        self.downsample = make_downsample\n",
    "        bottleneckedChannels = int (inChannels / BOTTLENECK_COEF)\n",
    "        \n",
    "        if not make_downsample:\n",
    "            self.conv1 = MoreComplicatedConvolutionalLayer(inChannels, bottleneckedChannels, BOTTLENECK_KERNEL)\n",
    "            self.conv2 = MoreComplicatedConvolutionalLayer(bottleneckedChannels, bottleneckedChannels)\n",
    "            self.conv3 = MoreComplicatedConvolutionalLayer(bottleneckedChannels, inChannels, BOTTLENECK_KERNEL, noRelu = True)\n",
    "            self.lastRelu = nn.LeakyReLU()\n",
    "        else:\n",
    "            self.conv1 = MoreComplicatedConvolutionalLayer(inChannels, bottleneckedChannels, BOTTLENECK_KERNEL)\n",
    "            self.conv2 = DownsamplingConvolutionalLayer(bottleneckedChannels)\n",
    "            self.conv3 = MoreComplicatedConvolutionalLayer(2 * bottleneckedChannels, 2 * inChannels, BOTTLENECK_KERNEL, noRelu = True)\n",
    "            self.lastRelu = nn.LeakyReLU()\n",
    "    \n",
    "            \n",
    "    def forward(self, x):\n",
    "        if self.use_skip_connection:\n",
    "            if self.downsample:\n",
    "                variableToSaveX = speciallyResizedX(x).to(torch.device(DEVICE))\n",
    "            else:\n",
    "                variableToSaveX = x.to(torch.device(DEVICE))\n",
    "            x = self.conv1(x)\n",
    "            x = self.conv2(x)\n",
    "            x = self.conv3(x)\n",
    "            x = self.lastRelu(x + variableToSaveX)\n",
    "        else:\n",
    "            x = self.conv1(x)\n",
    "            x = self.conv2(x)\n",
    "            x = self.conv3(x)\n",
    "            x = self.lastRelu(x)        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MaResNet, self).__init__()\n",
    "        \n",
    "        #TODO нужно добавить блоков resnet и других слоев при необходимости\n",
    "        \n",
    "        self.features = nn.Sequential()\n",
    "    \n",
    "        \n",
    "        self.features.add_module('first', MoreComplicatedConvolutionalLayer(3, 32))\n",
    "        self.features.add_module('res1', CifarResidualBottleneckBlock(32))\n",
    "        self.features.add_module('res2', CifarResidualBottleneckBlock(32))\n",
    "        self.features.add_module('res3', CifarResidualBottleneckBlock(32, make_downsample = True))\n",
    "        self.features.add_module('res4', CifarResidualBottleneckBlock(64))\n",
    "        self.features.add_module('res5', CifarResidualBottleneckBlock(64))\n",
    "        self.features.add_module('res6', CifarResidualBottleneckBlock(64))\n",
    "        self.features.add_module('res7', CifarResidualBottleneckBlock(64, make_downsample = True))\n",
    "        self.features.add_module('res8', CifarResidualBottleneckBlock(128))\n",
    "        self.features.add_module('res9', CifarResidualBottleneckBlock(128))\n",
    "        self.features.add_module('res10', CifarResidualBottleneckBlock(128))\n",
    "        self.features.add_module('res11', CifarResidualBottleneckBlock(128))\n",
    "        self.global_avg_pooling = nn.AvgPool2d(3, 2, 1)\n",
    "        self.fc_classifier = nn.Linear(128 * 4 * 4, 100)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.global_avg_pooling(x)        \n",
    "        x = x.view((x.size()[0], -1))        \n",
    "        x = self.fc_classifier(x)        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss = 1.3703\n",
      "Checking accuracy on validation set\n",
      "Got 592 / 1000 correct (59.20)\n",
      "\n",
      "epoch 1, loss = 0.9877\n",
      "Checking accuracy on validation set\n",
      "Got 582 / 1000 correct (58.20)\n",
      "\n",
      "epoch 2, loss = 1.3437\n",
      "Checking accuracy on validation set\n",
      "Got 598 / 1000 correct (59.80)\n",
      "\n",
      "epoch 3, loss = 1.0807\n",
      "Checking accuracy on validation set\n",
      "Got 597 / 1000 correct (59.70)\n",
      "\n",
      "epoch 4, loss = 1.4374\n",
      "Checking accuracy on validation set\n",
      "Got 564 / 1000 correct (56.40)\n",
      "\n",
      "epoch 5, loss = 1.0432\n",
      "Checking accuracy on validation set\n",
      "Got 576 / 1000 correct (57.60)\n",
      "\n",
      "epoch 6, loss = 1.0890\n",
      "Checking accuracy on validation set\n",
      "Got 582 / 1000 correct (58.20)\n",
      "\n",
      "epoch 7, loss = 1.1952\n",
      "Checking accuracy on validation set\n",
      "Got 591 / 1000 correct (59.10)\n",
      "\n",
      "epoch 8, loss = 1.2924\n",
      "Checking accuracy on validation set\n",
      "Got 573 / 1000 correct (57.30)\n",
      "\n",
      "epoch 9, loss = 1.3742\n",
      "Checking accuracy on validation set\n",
      "Got 581 / 1000 correct (58.10)\n",
      "\n",
      "epoch 10, loss = 1.1857\n",
      "Checking accuracy on validation set\n",
      "Got 577 / 1000 correct (57.70)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-a264024fb196>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#resnet.load_state_dict(torch.load(\"ResNetDump_1\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-70-a23f1df9465b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \"\"\"\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m# TODO: make efficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#resnet = MaResNet()\n",
    "#resnet.load_state_dict(torch.load(\"ResNetDump_Dubovik4\"))\n",
    "optimizer = torch.optim.SGD(resnet.parameters(), lr=0.0001, momentum=0.90)\n",
    "train(resnet, optimizer, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "на валидации такое серьезное отставание от итогового результата из-за значительного оверфита, полагаю, точность на трейне тут под 80-90, итог, достигнутый данной сеткой - 73.5 на kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet.state_dict(), \"ResNetDump_Dubovik4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Важно переключить сеть в режим eval - иначе dropout будет работать некорректно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_solution(a_net, a_device):\n",
    "    res = []\n",
    "    net = a_net.eval()\n",
    "    for item in dataloader_test_norm:\n",
    "        inputs = item.to(a_device)\n",
    "        outputs = net(inputs) \n",
    "\n",
    "        res += prediction2classes(outputs)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_solution = make_solution(dense_net, DEVICE)\n",
    "my_solution = make_solution(resnet.to(DEVICE), DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sunlution3.csv', 'w') as fout:\n",
    "    print('Id', 'Prediction', sep=',', file=fout)\n",
    "    for i, prediction in enumerate(my_solution):\n",
    "        print(i, prediction, sep=',', file=fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
